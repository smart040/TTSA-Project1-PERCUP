{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696825b6-4357-4595-81ac-808dd80ca186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ripser import ripser\n",
    "from persim import plot_diagrams\n",
    "import tadasets\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "#Here we are just generating a torus\n",
    "np.random.seed(2)\n",
    "n_data = 25000\n",
    "R = 5\n",
    "r = 2\n",
    "data = np.zeros((3, n_data))\n",
    "s = np.random.rand(n_data)*2*np.pi\n",
    "t = np.random.rand(n_data)*2*np.pi\n",
    "\n",
    "data[0] = (R + r*np.cos(s))*np.cos(t)\n",
    "data[1] = (R + r*np.cos(s))*np.sin(t)\n",
    "data[2] = r*np.sin(s)\n",
    "data += 0.1*np.random.randn(*data.shape)\n",
    "\n",
    "\n",
    "#This is sampling to reduce the number of points that I have to work with\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_downsampling(data, num_points):\n",
    "    # Perform k-means clustering on the data\n",
    "    kmeans = KMeans(n_clusters=num_points, random_state=0).fit(data)\n",
    "    \n",
    "    # Get the centroids of the clusters\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "# Set the desired number of points after downsampling\n",
    "num_points = 100 #This seems to be a good sample size that keeps al of the important data\n",
    "\n",
    "# Perform k-means downsampling on the data\n",
    "x = kmeans_downsampling(data.T, num_points)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#First lets see what triangles actually exist, and if they do exist then we can mulitply\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af16c34-865a-4aa3-adfd-5e11f668ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is just to get everything ready\n",
    "plt.scatter(x[:, 0], x[:, 1])\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "result = ripser(x, coeff=2, do_cocycles=True)\n",
    "diagrams = result['dgms']\n",
    "cocycles = result['cocycles'] #all of the cocycles\n",
    "D = result['dperm2all'] #distance matrix between the ith and jth points in the data\n",
    "dgm1 = diagrams[1]\n",
    "\n",
    "\n",
    "#This is the start for the highest point in the persistence diagram\n",
    "idx = np.argmax(dgm1[:, 1] - dgm1[:, 0])\n",
    "plot_diagrams(diagrams, show = False)\n",
    "plt.scatter(dgm1[idx, 0], dgm1[idx, 1], 20, 'k', 'x')\n",
    "plt.gca().add_patch(plt.Circle((dgm1[idx, 0], dgm1[idx, 1]), 0.5, color='r', fill=False))\n",
    "plt.title(\"Max 1D birth = %.3g, death = %.3g\"%(dgm1[idx, 0], dgm1[idx, 1]))\n",
    "plt.show()\n",
    "cocycle1 = cocycles[1][idx] #I think that this is the representative cocycle for the highest point\n",
    "\n",
    "#Now we just have to find the representative cocycle for psi so we have to look for the second highest point\n",
    "sorted_indices = np.argsort(dgm1[:, 1] - dgm1[:, 0])\n",
    "idx = sorted_indices[-2] #this will give me the second highest persistent point\n",
    "plot_diagrams(diagrams, show = False)\n",
    "plt.scatter(dgm1[idx, 0], dgm1[idx, 1], 20, 'k', 'x')\n",
    "plt.gca().add_patch(plt.Circle((dgm1[idx, 0], dgm1[idx, 1]), 0.5, color='r', fill=False))\n",
    "plt.title(\"Max 1D birth = %.3g, death = %.3g\"%(dgm1[idx, 0], dgm1[idx, 1]))\n",
    "plt.show()\n",
    "cocycle2 = cocycles[1][idx] #I think that this is the representative cocyle for the second highest persistent point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f46880-4365-4bb1-be09-fa4f1b3c70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For cocycle1 we want to restrict it to cocycle2\n",
    "\n",
    "\n",
    "New_cocycle1=[]\n",
    "edges=[]\n",
    "for i in range(len(cocycle1)):\n",
    "        for j in range(len(cocycle2)):\n",
    "            if np.array_equal(cocycle1[i:i-1, :2], cocycle1[i:i+1, :2], cocycle2[j:j+1, :2]): #This checks to see if there are any edges in common \n",
    "                New_cocycle1.append(cocycle2[j:j+1])\n",
    "        New_cocycle1.append(cocycle2[i:i+1])        \n",
    "rcocycle1=np.vstack(New_cocycle1)\n",
    "\n",
    "#Now I have to go back to collect the edges in common:\n",
    "\n",
    "for i in range(len(cocycle1)):\n",
    "        for j in range(len(cocycle2)):\n",
    "            if np.array_equal(cocycle1[i-1:i, :2], cocycle2[j:j+1, :2]):\n",
    "                edges.append(cocycle2[j:j+1])\n",
    "                \n",
    "edges=np.vstack(edges)\n",
    "\n",
    "\n",
    "\n",
    "#Finally I have to make the rows that are not equal to any of the edges columns be zero\n",
    "for i in range(len(rcocycle1)):\n",
    "    found_match = False\n",
    "\n",
    "    for j in range(len(edges)):\n",
    "        if np.array_equal(rcocycle1[i, :2], edges[j, :2]):\n",
    "            found_match = True\n",
    "            break\n",
    "\n",
    "    if not found_match:\n",
    "        rcocycle1[i, -1] = 0\n",
    "\n",
    "#Checking to see if the dimensions are correct\n",
    "print(\"Length of Restricted Cocycle 1\")            \n",
    "print(len(rcocycle1))\n",
    "print(\"Length of Cocycle 2\")\n",
    "print(len(cocycle2))\n",
    "print(\"Edges that are in common\")\n",
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606962f8-00e4-4bbc-8611-7428740c3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok ok now we can start taking the cup product\n",
    "\n",
    "#so we have phi and psi, now we need to extract every traingle {a,b,c} then take phi(rcocycle1) of the first two {a,b} then psi(cocycle2) of the last two verticies {b,c}\n",
    "\n",
    "#First we have to get all of the triangles:\n",
    "\n",
    "# Finding the representative cocycles for triangles\n",
    "from itertools import combinations\n",
    "\n",
    "representative_cocycles = []\n",
    "\n",
    "for i in range(len(dgm1)):\n",
    "    birth, death = dgm1[i]\n",
    "    if birth != death:  # ignore points on the diagonal\n",
    "        cocycle = cocycles[1][i]\n",
    "        representative_cocycles.append(cocycle)\n",
    "\n",
    "# Extracting every triangle as an array of vertices\n",
    "triangles = []\n",
    "\n",
    "for cocycle in representative_cocycles:\n",
    "    edge_indices = cocycle[:, :2].astype(int)\n",
    "    triangle_vertices = set()\n",
    "    \n",
    "    for i, j in edge_indices:\n",
    "        triangle_vertices.add(i)\n",
    "        triangle_vertices.add(j)\n",
    "    \n",
    "    # Generate all combinations of 3 vertices\n",
    "    triangle_combinations = combinations(triangle_vertices, 3)\n",
    "    \n",
    "    for combination in triangle_combinations:\n",
    "        triangles.append(list(combination))\n",
    "\n",
    "\n",
    "t=np.vstack(triangles)\n",
    "print(\"Number of triangles we have to look through\")\n",
    "print(len(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02b797-4564-4192-b947-b630a763dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cup product function\n",
    "\n",
    "def cupProduct(phi, psi, triangleList):\n",
    "    cupProduct = []\n",
    "    for i in range(len(triangleList)):\n",
    "        phiVal = 0\n",
    "        psiVal = 0\n",
    "        for j in range(len(phi)):\n",
    "            if phi[j][0] == triangleList[i][0] and phi[j][1] == triangleList[i][1]:\n",
    "                phiVal = phi[j][2]\n",
    "                break;\n",
    "        for k in range(len(psi)):\n",
    "            if psi[k][0] == triangleList[i][1] and psi[k][1] == triangleList[i][2]:\n",
    "                psiVal = psi[k][2]\n",
    "                break;\n",
    "        cupProduct.append(phiVal * psiVal)\n",
    "    cupProduct = np.array(cupProduct).T\n",
    "    return cupProduct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5532786-cfc7-4382-a0b4-1ab0278e747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cup=cupProduct(rcocycle1,cocycle2, t)\n",
    "cup=np.vstack(cup)\n",
    "print(\"Cup Product:\")\n",
    "print(cup)\n",
    "print(\"Confirm dimension is the same\")\n",
    "print(len(cup))\n",
    "time_e=time.time()-start_time\n",
    "print(\"Time elasped\")\n",
    "print(time_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81eb3a-e59b-41d2-8c6d-4181da2e6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to compute the boundary matrix from ripser, going with the same approach that I had for gudhi but just not with gudhi\n",
    "#Already got the triangles but will just do it again and extract all vertices, edges, and triangles\n",
    "\n",
    "edges = []\n",
    "triangles = []\n",
    "vertices=[]\n",
    "\n",
    "#Triangles\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "representative_cocycles = []\n",
    "\n",
    "for i in range(len(dgm1)):\n",
    "    birth, death = dgm1[i]\n",
    "    if birth != death:  # ignore points on the diagonal\n",
    "        cocycle = cocycles[1][i]\n",
    "        representative_cocycles.append(cocycle)\n",
    "\n",
    "# Extracting every triangle as an array of vertices\n",
    "\n",
    "for cocycle in representative_cocycles:\n",
    "    edge_indices = cocycle[:, :2].astype(int)\n",
    "    triangle_vertices = set()\n",
    "    \n",
    "    for i, j in edge_indices:\n",
    "        triangle_vertices.add(i)\n",
    "        triangle_vertices.add(j)\n",
    "    \n",
    "    # Generate all combinations of 3 vertices\n",
    "    triangle_combinations = combinations(triangle_vertices, 3)\n",
    "    \n",
    "    for combination in triangle_combinations:\n",
    "        triangles.append(list(combination))\n",
    "\n",
    "# Extracting every edge as an array of vertices\n",
    "\n",
    "for cocycle in representative_cocycles:\n",
    "    edge_indices = cocycle[:, :2].astype(int)\n",
    "    for i, j in edge_indices:\n",
    "        edge = [i, j]\n",
    "        edges.append(edge)\n",
    "        \n",
    "#Gettin the vertices\n",
    "for cocycle in representative_cocycles:\n",
    "    vertex_indices = cocycle[:, :1].astype(int)\n",
    "    for i in vertex_indices:\n",
    "        vertices.append(i[0])\n",
    "        \n",
    "# Remove duplicate vertices by converting the list to a set and then back to a list\n",
    "vertices = list(set(vertices))\n",
    "        \n",
    "print(\"Vertices\")\n",
    "print(vertices)\n",
    "print(\"Length of vertices\")\n",
    "print(len(vertices))\n",
    "print(\"Edges\")\n",
    "print(edges)\n",
    "print(\"Length of edges\")\n",
    "print(len(edges))\n",
    "print(\"Triangles\")\n",
    "#print(triangles) #This is too long to print \n",
    "print(\"Length of triangles\")\n",
    "print(len(triangles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c2318-f063-4f85-a864-bdbfa1356383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aight now that I have that, we can contruct the boundary matrix\n",
    "\n",
    "#Create a boundary Matrix        \n",
    "ne = len(edges)\n",
    "nt = len(triangles)\n",
    "nv = len(vertices)\n",
    "\n",
    "num_rows= ne+nt+nv\n",
    "num_cols=ne+nt+nv\n",
    "\n",
    "boundary_matrix=np.zeros((num_rows, num_cols), dtype=int)\n",
    "\n",
    "\n",
    "#Split it up and just deal with the edges and verticies first because the triangles are going to zero out, same will happen with the edges and edges and verticies and verticies\n",
    "\n",
    "for i,edge in enumerate(edges):\n",
    "    a,b=edge #a and b are the two verticies that make up the edge\n",
    "    for j,vertex in enumerate(vertices):\n",
    "        c=vertex # c d and e are the verticies that make up the triangle\n",
    "        if b == c:\n",
    "            boundary_matrix[nv+i,j]=1\n",
    "        if a == c:\n",
    "            boundary_matrix[nv+i,j]=-1\n",
    "        \n",
    "        \n",
    "#now deal with the edges and verticies\n",
    "for i, triangle in enumerate(triangles):\n",
    "    e,f,g=triangle #e,f,g are verticies in the triangle\n",
    "    for j,edge in enumerate(edges):\n",
    "        h,k=edge\n",
    "        if (h,k) == (e,f):\n",
    "            boundary_matrix[(ne+nv)+i,nv+j]=1\n",
    "        if (h,k) == (f,g):\n",
    "            boundary_matrix[(ne+nv)+i,nv+j]=1\n",
    "        if (h,k) == (e,g):\n",
    "            boundary_matrix[(ne+nv)+i,nv+j]=-1\n",
    "\n",
    "print(\"Boundary Matrix:\")\n",
    "boundary_matrix=boundary_matrix.T\n",
    "print(boundary_matrix)\n",
    "print(len(boundary_matrix))\n",
    "print(len(boundary_matrix[0]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143cea36-0388-42dc-9bcf-4460e54e0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_matrix = boundary_matrix[nv:nv + ne, nv + ne:len(boundary_matrix)]\n",
    "coboundary_matrix = np.flip(restricted_matrix).T\n",
    "print(\"Coboundary Matrix\")\n",
    "print(coboundary_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b079cfe-025b-4c63-883e-10064ec52d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows (triangles)\")\n",
    "print(len(coboundary_matrix))\n",
    "print(\"Number of columns (edges)\")\n",
    "print(len(coboundary_matrix[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
